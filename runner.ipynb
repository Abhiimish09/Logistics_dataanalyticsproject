{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":700,"status":"ok","timestamp":1715251883007,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"nf2x6paG5_Pl"},"outputs":[],"source":["work_dir = '/content/drive/MyDrive/logistics__yolo'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6594,"status":"ok","timestamp":1715251891713,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"Ch_7UHB7-KWX"},"outputs":[],"source":["!pip install ultralytics -q"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5781,"status":"ok","timestamp":1715251905900,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"X0i3Lq0W-S4G"},"outputs":[],"source":["!pip install datasets[vision] -q"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5837,"status":"ok","timestamp":1715251917765,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"mKVw0buX7dFi"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import warnings\n","import matplotlib.pyplot as plt\n","import yaml\n","from PIL import Image\n","import os\n","import seaborn as sns\n","from ultralytics import YOLO\n","from matplotlib.patches import Rectangle\n","import glob\n","import cv2\n","import os\n","import yaml\n","import shutil\n","import random\n","import ultralytics\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1715251924012,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"1Nyc7M5A-8VA"},"outputs":[],"source":["def log(msg):\n","    print(f'🔔---| {msg} ')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715251931319,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"GTf-599M_Htn"},"outputs":[],"source":["#create file paths for the training and validation sets\n","train_path_img = \"/content/drive/MyDrive/logistics project/data_from_roboflow/train/images\"\n","train_path_label = \"/content/drive/MyDrive/logistics project/data_from_roboflow/train/labels\"\n","val_path_img = \"/content/drive/MyDrive/logistics project/data_from_roboflow/valid/images/\"\n","val_path_label = \"/content/drive/MyDrive/logistics project/data_from_roboflow/valid/labels/\"\n","test_path_img = \"/content/drive/MyDrive/logistics project/data_from_roboflow/test/images\"\n","test_path_label = \"/content/drive/MyDrive/logistics project/data_from_roboflow/test/labels\"\n","\n","def get_random(validation_path):\n","    #get a random image from the validation set\n","    random_indexes  = random.sample(range(0, len(os.listdir(validation_path))), k=10)\n","    # create a folder inside data/waste_data/ to store test images and labels\n","    os.makedirs(\"data/waste_data/test/images\", exist_ok=True)\n","    os.makedirs(\"data/waste_data/test/labels\", exist_ok=True)\n","    # move the random image and labels to the test folder\n","    for i in random_indexes:\n","        image = os.listdir(validation_path)[i]\n","        shutil.move(validation_path + image, test_path_img + image)\n","        label = image.replace(\".jpg\", \".txt\")\n","        shutil.move(val_path_label + label, test_path_label + label)\n","        log(f\"Moved {image} and {label} to test folder\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1715251937699,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"oqSe013-_yLA","outputId":"866a0248-1fe9-4b93-8325-82012fdd132b"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔔---| Number of training images: 2707 \n","🔔---| Number of validation images: 173 \n","🔔---| Number of test images: 124 \n"]}],"source":["# count the number of files in the training and validation sets\n","train_files = os.listdir(train_path_img)\n","val_files = os.listdir(val_path_img)\n","log(f\"Number of training images: {len(train_files)}\")\n","log(f\"Number of validation images: {len(val_files)}\")\n","log(f\"Number of test images: {len(os.listdir(test_path_img))}\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":571,"status":"ok","timestamp":1715251945460,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"egwTRDMO_2Qm"},"outputs":[],"source":["data_path = '/content/drive/MyDrive/logistics project/data_from_roboflow/data.yaml'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1715251951423,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"43lBru8EAIHA","outputId":"8dd365a9-0aae-488c-98fe-81b75871f15c"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔔---| Pytorch version: 2.2.1+cu121 \n","🔔---| Device: cpu \n"]}],"source":["import torch\n","# torch version\n","log(f\"Pytorch version: {torch.__version__}\")\n","\n","# check if CUDA is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","log(f\"Device: {device}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":567,"status":"ok","timestamp":1715251956735,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"iG9X0zJoAkab"},"outputs":[],"source":["os.environ['KMP_DUPLICATE_LIB_OK']='True' # for transformer models"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":555,"status":"ok","timestamp":1715251961703,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"ViwMVAyeAnS3"},"outputs":[],"source":["model = ultralytics.YOLO('yolov8m-obb.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qs1IfpCAoue","outputId":"a14b38b7-c496-4113-c538-7fb2bc0421c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.11 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (AMD EPYC 7B12)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolov8m-obb.pt, data=/content/drive/MyDrive/logistics project/data_from_roboflow/data.yaml, epochs=100, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/logistics project/runs, name=logistics5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/logistics project/runs/logistics5\n","Overriding model.yaml nc=15 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   4338028  ultralytics.nn.modules.head.OBB              [3, 1, [192, 384, 576]]       \n","YOLOv8m-obb summary: 320 layers, 26418652 parameters, 26418636 gradients, 81.2 GFLOPs\n","\n","Transferred 511/517 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/logistics project/runs/logistics5', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/logistics project/data_from_roboflow/train/labels.cache... 2697 images, 261 backgrounds, 8 corrupt: 100%|██████████| 2707/2707 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.00a4c4fbb6c323e0d4ebf8cbca9800fc.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0311]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.231dd088e414a36a6f99678e1d205a92.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0754         1.1]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.a21180f51fab99f7622bd466693cfbc2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1639      1.2012]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.a4efc2c6c1de8717eec5ddab9750a643.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1468      1.1927]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.c751d289377a5cc2ba039ab6e06e6f51.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0494      1.0107]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130636-848_jpeg.rf.ca6d4c1dff5f4e10512967ed223c1c4f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1079      1.1962]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130644-802_jpeg.rf.a472a65d38d2e01c8d85167522460fc5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.008]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/logistics project/data_from_roboflow/train/images/images-2024-05-03T130644-802_jpeg.rf.f92897ffad5fd5940545dd7143431011.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0024]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/logistics project/data_from_roboflow/valid/labels.cache... 173 images, 15 backgrounds, 0 corrupt: 100%|██████████| 173/173 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to /content/drive/MyDrive/logistics project/runs/logistics5/labels.jpg... \n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 83 weight(decay=0.0), 93 weight(decay=0.0005), 92 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/logistics project/runs/logistics5\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/169 [00:00<?, ?it/s]"]}],"source":["model.train(\n","    data=data_path,        # dataset.yaml file\n","    task='detect',              # 'detect', 'segment', 'class'\n","    imgsz=640,                  # image size\n","    epochs=100,                  # number of epochs\n","    # workers=0,                  # number of workers\n","    batch=16,                   # batch size\n","    patience=20,                # early stopping patience\n","    project='/content/drive/MyDrive/logistics project/runs',             # save results to project/name\n","    mode='train',               # 'train', 'val', 'test'\n","    name='logistics',     # save results to project/name\n","    save=True,                  # save results to project/name/weights/last.pt\n","                    # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12858,"status":"ok","timestamp":1715252089821,"user":{"displayName":"Abhishek. Mishra.","userId":"07003443234347189566"},"user_tz":-330},"id":"zdGelkUZA7Bw","outputId":"5e02a8d5-d6fe-42ce-f601-195b12c2a907"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n","100% 49.7M/49.7M [00:00<00:00, 64.8MB/s]\n","Ultralytics YOLOv8.2.11 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (AMD EPYC 7B12)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/MyDrive/yolo_projects/dataset.yaml, epochs=5, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/yolo_projects/waste_detection, name=yolo, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolo_projects/waste_detection/yolo\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 517, in get_dataset\n","    data = check_det_dataset(self.args.data)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\", line 269, in check_det_dataset\n","    file = check_file(dataset)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\", line 506, in check_file\n","    raise FileNotFoundError(f\"'{file}' does not exist\")\n","FileNotFoundError: '/content/drive/MyDrive/yolo_projects/dataset.yaml' does not exist\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 583, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 654, in train\n","    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 130, in __init__\n","    self.trainset, self.testset = self.get_dataset()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 521, in get_dataset\n","    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\")) from e\n","RuntimeError: Dataset '/content/drive/MyDrive/yolo_projects/dataset.yaml' error ❌ '/content/drive/MyDrive/yolo_projects/dataset.yaml' does not exist\n"]}],"source":["!yolo task=detect mode=train model=yolov8m.pt data=/content/drive/MyDrive/yolo_projects/dataset.yaml epochs=5 imgsz=640 batch=16 patience=20 project=/content/drive/MyDrive/yolo_projects/waste_detection name=yolo\n","\n","# comment the code above and uncomment the code below to resume training if notebook is interupted\n","# Note: you will need to run all the previous lines of code\n","# !yolo task=detect mode=train resume data=/content/drive/MyDrive/Garbage_Detection/dataset.yaml model=/content/drive/MyDrive/Garbage_Detection/training_results/weights/last.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3R6IYqp_Zww"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
